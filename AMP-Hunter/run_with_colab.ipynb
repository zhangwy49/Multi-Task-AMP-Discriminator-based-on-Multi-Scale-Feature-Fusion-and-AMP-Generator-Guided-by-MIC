{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Environment"
      ],
      "metadata": {
        "id": "Y6Cs78G3uH_O"
      },
      "id": "Y6Cs78G3uH_O"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "b399fe72",
      "metadata": {
        "id": "b399fe72",
        "outputId": "f4491e67-6b3b-46be-8fea-3dfd01cefe89",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'AMP-potency-prediction-EvoGradient'...\n",
            "remote: Enumerating objects: 97, done.\u001b[K\n",
            "remote: Counting objects: 100% (97/97), done.\u001b[K\n",
            "remote: Compressing objects: 100% (68/68), done.\u001b[K\n",
            "remote: Total 97 (delta 30), reused 88 (delta 26), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (97/97), 17.16 MiB | 24.07 MiB/s, done.\n",
            "Resolving deltas: 100% (30/30), done.\n",
            "/content/AMP-potency-prediction-EvoGradient\n"
          ]
        }
      ],
      "source": [
        "# clone our github repo\n",
        "!git clone https://github.com/MicroResearchLab/AMP-potency-prediction-EvoGradient.git\n",
        "%cd AMP-potency-prediction-EvoGradient/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install biopython==1.81 # Based on the default Colab environment, you only need to install Biopython to run our code."
      ],
      "metadata": {
        "id": "MCIdXB67Vqf5",
        "outputId": "414432f0-4019-4842-e7ea-52dd73aebf45",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "MCIdXB67Vqf5",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting biopython==1.81\n",
            "  Downloading biopython-1.81-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from biopython==1.81) (2.0.2)\n",
            "Downloading biopython-1.81-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/3.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m132.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m73.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: biopython\n",
            "Successfully installed biopython-1.81\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AMP-CLIP"
      ],
      "metadata": {
        "id": "5szz2RpHuDpH"
      },
      "id": "5szz2RpHuDpH"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "import math\n",
        "import argparse\n",
        "from Bio import SeqIO\n",
        "\n",
        "# Parse command-line arguments\n",
        "parser = argparse.ArgumentParser(description=\"AMP Classification\")\n",
        "parser.add_argument(\"--testPath\", type=str, default='./data/classification/demo.fasta', help=\"Path to the test dataset\")\n",
        "parser.add_argument(\"--savePath\", type=str, default='output/classification_result.csv', help=\"Path to save the results\")\n",
        "# args = parser.parse_args()\n",
        "args, unknown = parser.parse_known_args()\n",
        "\n",
        "testPath = args.testPath\n",
        "savePath = args.savePath\n",
        "\n",
        "# Data paths\n",
        "trainPath = \"./data/classification/train.csv\"\n",
        "validatePath = \"./data/classification/test.csv\"\n",
        "\n",
        "# Configuration parameters\n",
        "batch_size = 256\n",
        "embedding_size = 20\n",
        "num_tokens = 100\n",
        "num_classes = 2\n",
        "num_heads = 4\n",
        "\n",
        "# Model paths\n",
        "model_list = {\n",
        "    \"CNN\": \"./model/classification/CNN.pth\",\n",
        "    \"Transformer\": \"./model/classification/Transformer.pth\",\n",
        "    \"Attention\": \"./model/classification/Attention.pth\",\n",
        "    \"LSTM\": \"./model/classification/LSTM.pth\",\n",
        "}\n",
        "nameList = model_list.keys()\n",
        "\n",
        "# Sequence to numerical mapping\n",
        "mydict = {\"A\": 0, \"C\": 1, \"D\": 2, \"E\": 3, \"F\": 4, \"G\": 5, \"H\": 6, \"I\": 7, \"K\": 8, \"L\": 9, \"M\": 10, \"N\": 11, \"P\": 12, \"Q\": 13, \"R\": 14, \"S\": 15, \"T\": 16, \"V\": 17, \"W\": 18, \"Y\": 19}\n",
        "\n",
        "softmax = nn.functional.softmax\n",
        "\n",
        "\n",
        "def fasta_to_csv(fasta_path, csv_path):\n",
        "    \"\"\"\n",
        "    Convert a FASTA file to a CSV file.\n",
        "\n",
        "    Parameters:\n",
        "    fasta_path (str): Path to the input FASTA file.\n",
        "    csv_path (str): Path to the output CSV file.\n",
        "\n",
        "    Returns:\n",
        "    str: Path to the output CSV file.\n",
        "    \"\"\"\n",
        "    sequences = []\n",
        "    lengths = []\n",
        "\n",
        "    # Parse the FASTA file and extract sequences and their lengths\n",
        "    for record in SeqIO.parse(fasta_path, \"fasta\"):\n",
        "        sequences.append(str(record.seq))\n",
        "        lengths.append(len(record.seq))\n",
        "\n",
        "    # Create a DataFrame with sequences and their lengths\n",
        "    df = pd.DataFrame({\"Sequence\": sequences, \"Length\": lengths})\n",
        "\n",
        "    # Save the DataFrame to a CSV file\n",
        "    print(csv_path)\n",
        "    df.to_csv(csv_path, index=False)\n",
        "    return csv_path\n",
        "\n",
        "\n",
        "# Transform the test FASTA file to CSV\n",
        "testPath = fasta_to_csv(testPath, testPath[:-5] + \".csv\")\n",
        "\n",
        "\n",
        "def dataProcessPipeline(seq):\n",
        "    \"\"\"\n",
        "    Process a sequence into a padded one-hot encoded tensor and a mask.\n",
        "\n",
        "    Parameters:\n",
        "    seq (str): The input sequence to process.\n",
        "\n",
        "    Returns:\n",
        "    tuple: A tuple containing the padded one-hot encoded tensor and the mask tensor.\n",
        "    \"\"\"\n",
        "    testest = seq\n",
        "    num_seq = [mydict[character.upper()] for character in seq]\n",
        "\n",
        "    seq = np.array(num_seq, dtype=int)\n",
        "    len = seq.shape[0]\n",
        "    torch_seq = torch.tensor(seq)\n",
        "\n",
        "    if torch.sum(torch_seq[torch_seq < 0]) != 0:\n",
        "        print(torch_seq[torch_seq < 0])\n",
        "        print(\"wrong seq:\", seq)\n",
        "        print(testest)\n",
        "\n",
        "    onehotSeq = torch.nn.functional.one_hot(torch_seq, num_classes=20)\n",
        "    # Pad the sequence to a length of 100\n",
        "    pad = torch.nn.ZeroPad2d(padding=(0, 0, 0, 100 - len))\n",
        "    mask = np.zeros(100, dtype=int)\n",
        "    mask[len:] = 1\n",
        "    mask = torch.tensor(mask)\n",
        "    pad_seq = pad(onehotSeq)\n",
        "\n",
        "    return pad_seq, mask\n",
        "\n",
        "\n",
        "# train dataset\n",
        "class TrainDataset(Dataset):\n",
        "    def __init__(self, data_path):\n",
        "        df = pd.read_csv(data_path, header=0)\n",
        "        df = df[df[\"Length\"] <= 100]\n",
        "        self.seqs = list(df[\"Sequence\"])\n",
        "        self.labels = list(df[\"label\"])\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        seq = self.seqs[index]\n",
        "        num_seq, mask = dataProcessPipeline(seq)\n",
        "        label = self.labels[index]\n",
        "        return num_seq, mask, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.seqs)\n",
        "\n",
        "\n",
        "# test dataset\n",
        "class TestDataset(Dataset):\n",
        "    def __init__(self, data_path):\n",
        "        df = pd.read_csv(data_path, header=0).reset_index()\n",
        "        self.seqs = df[\"Sequence\"]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        seq = self.seqs[index]\n",
        "        num_seq, mask = dataProcessPipeline(seq)\n",
        "        return num_seq, mask, seq\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.seqs)\n",
        "\n",
        "\n",
        "class FastaDataset(Dataset):\n",
        "    def __init__(self, data_path, transform=dataProcessPipeline):\n",
        "        \"\"\"\n",
        "        Initialize the dataset from a FASTA file.\n",
        "\n",
        "        Parameters:\n",
        "        data_path (str): Path to the FASTA file.\n",
        "        transform (function): Function to process the sequences.\n",
        "        \"\"\"\n",
        "        self.seqs = [record.seq for record in SeqIO.parse(data_path, \"fasta\")]\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        seq = str(self.seqs[index])\n",
        "        num_seq, mask = self.transform(seq)\n",
        "        return num_seq, mask, seq\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.seqs)\n",
        "\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, length, d_model=20):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        pe = torch.zeros(length, d_model)\n",
        "        position = torch.arange(0, length, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        self.register_buffer(\"pe\", pe.unsqueeze(0))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe\n",
        "        return x\n",
        "\n",
        "\n",
        "\"\"\"attention model\"\"\"\n",
        "\n",
        "\n",
        "class AttentionNetwork(nn.Module):\n",
        "\n",
        "    def __init__(self, batch_size=128, embedding_size=20, num_tokens=100, num_classes=2, num_heads=4):\n",
        "\n",
        "        super(AttentionNetwork, self).__init__()\n",
        "        self.pe = PositionalEncoding(len=num_tokens, d_model=embedding_size)\n",
        "\n",
        "        self.batch_size = batch_size\n",
        "        self.embedding_size = embedding_size\n",
        "        self.num_tokens = num_tokens\n",
        "        self.num_classes = num_classes\n",
        "        self.num_heads = num_heads\n",
        "\n",
        "        self.hidden1 = 20\n",
        "        self.hidden2 = 60\n",
        "        self.hidden3 = 20\n",
        "        self.dropout = 0.5\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "        self.LN = nn.LayerNorm(normalized_shape=self.hidden1)\n",
        "        self.fc1 = nn.Linear(self.embedding_size, self.hidden1)\n",
        "        self.multihead_att = nn.MultiheadAttention(embed_dim=self.hidden1, num_heads=self.num_heads, batch_first=1, dropout=self.dropout)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc2 = nn.Linear(self.hidden1 * self.num_tokens, self.hidden2)\n",
        "        self.fc3 = nn.Linear(self.hidden2, self.hidden3)\n",
        "        self.fc4 = nn.Linear(self.hidden3, self.num_classes)\n",
        "        self.dropout = nn.Dropout(self.dropout)\n",
        "        self.softmax = nn.functional.softmax\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        x = self.pe(x)\n",
        "        x = self.fc1(x)\n",
        "\n",
        "        mask = mask.to(torch.bool)\n",
        "        x, _ = self.multihead_att.forward(x, x, x, key_padding_mask=mask)\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.relu(x)\n",
        "        x = self.fc3(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc4(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "trainData = TrainDataset(data_path=trainPath)\n",
        "validateData = TrainDataset(data_path=validatePath)\n",
        "testData = TestDataset(data_path=testPath)\n",
        "\n",
        "train_loader = DataLoader(dataset=trainData, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(dataset=testData, batch_size=batch_size, shuffle=False)\n",
        "validate_loader = DataLoader(dataset=validateData, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "loss_function = nn.MSELoss()\n",
        "\n",
        "result_df = pd.read_csv(testPath, header=0)\n",
        "\n",
        "model_out = {}\n",
        "# process with all the models\n",
        "for modelName in nameList:\n",
        "    modelPath = model_list[modelName]\n",
        "    id = modelPath.split(\"/\")[-2]\n",
        "    model_out[modelName] = []\n",
        "\n",
        "    t_model = torch.load(modelPath, weights_only=False, map_location='cpu')\n",
        "    t_model.cpu()\n",
        "    if modelName == \"Transformer\":\n",
        "        t_model.postion_embedding.device = \"cpu\"\n",
        "\n",
        "    # evaluate models\n",
        "    def score(test_loader):\n",
        "        t_model.eval()\n",
        "        epi = 0.000001\n",
        "        tp = 0\n",
        "        tn = 0\n",
        "        fp = 0\n",
        "        fn = 0\n",
        "        total = 0\n",
        "        count = 0\n",
        "\n",
        "        for data in test_loader:\n",
        "            inputs, masks, labels = data\n",
        "            inputs = inputs.float()\n",
        "            masks = masks.float()\n",
        "            inputs, masks, labels = Variable(inputs), Variable(masks), Variable(labels)\n",
        "\n",
        "            inputs = inputs.cpu()\n",
        "            masks = masks.cpu()\n",
        "\n",
        "            if modelName != \"Attention\" and modelName != \"Transformer2\":\n",
        "                out = t_model(inputs)\n",
        "            else:\n",
        "                out = t_model(inputs, masks)\n",
        "            out = torch.squeeze(out)\n",
        "\n",
        "            out = torch.argmax(out, -1)\n",
        "            out = out.cpu()\n",
        "            for i, pre in enumerate(out):\n",
        "                total += 1\n",
        "                if pre == labels[i]:\n",
        "                    count += 1\n",
        "                    if pre == 0:\n",
        "                        tn += 1\n",
        "                    else:\n",
        "                        tp += 1\n",
        "                if pre != labels[i]:\n",
        "                    if pre == 0:\n",
        "                        fn += 1\n",
        "                    else:\n",
        "                        fp += 1\n",
        "\n",
        "        print(\"AMP classification result:\")\n",
        "        print(\"Precision:\", np.round(tp / (tp + fp + epi), 3))\n",
        "        print(\"Recall:\", np.round(tp / (tp + fn + epi), 3))\n",
        "        print(\"Specificity:\", np.round(tn / (tn + fp + epi), 3))\n",
        "        print(\"F1:\", np.round(2 * tp / (2 * tp + fp + fn + epi), 3))\n",
        "        print(\"Accuracy：\", np.round(count / total, 3))\n",
        "        print()\n",
        "\n",
        "    print()\n",
        "    print(\"Model:\", modelName)\n",
        "    score(validate_loader)\n",
        "\n",
        "    # use model to predict test data\n",
        "    for i, data in enumerate(test_loader):\n",
        "        inputs, masks, seqs = data\n",
        "        inputs = inputs.float()\n",
        "        masks = masks.float()\n",
        "\n",
        "        t_model.eval()\n",
        "        inputs = inputs.cpu()\n",
        "        masks = masks.cpu()\n",
        "        if modelName != \"Attention\":\n",
        "            out = t_model(inputs)\n",
        "        else:\n",
        "            out = t_model(inputs, masks)\n",
        "\n",
        "        out = out.cpu()\n",
        "        if \"LSTM\" in modelName:\n",
        "            out = out.unsqueeze(0)\n",
        "        out_ori = torch.squeeze(out)\n",
        "\n",
        "        out_ori = torch.squeeze(out)\n",
        "        out_soft = softmax(out_ori, -1)\n",
        "        out_soft_AMP = out_soft[:, 1]\n",
        "\n",
        "        out_soft_numpy = list(out_soft_AMP.detach().numpy())\n",
        "        out_soft_numpy = [round(v, 3) for v in out_soft_numpy]\n",
        "        model_out[modelName] = list(model_out[modelName]) + out_soft_numpy\n",
        "\n",
        "# summarize the results\n",
        "for k, v in model_out.items():\n",
        "    result_df[k] = v\n",
        "\n",
        "result_df = result_df[[\"Sequence\", \"CNN\", \"Transformer\", \"Attention\", \"LSTM\"]]\n",
        "\n",
        "y = (result_df[\"CNN\"] > 0.5) * (result_df[\"Transformer\"] > 0.5) * (result_df[\"LSTM\"] > 0.5) * (result_df[\"Attention\"] > 0.5)\n",
        "result_df[\"Ensemble\"] = y\n",
        "\n",
        "result_df.to_csv(savePath, index=0)\n",
        "print(result_df)\n",
        "print(f\"Test result is saved to ./{savePath} \")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "laYRpQrTb8__",
        "outputId": "beccff77-e803-4705-8719-95dfc03f2b88"
      },
      "id": "laYRpQrTb8__",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "./data/classification/demo..csv\n",
            "\n",
            "Model: CNN\n",
            "AMP classification result:\n",
            "Precision: 0.982\n",
            "Recall: 0.843\n",
            "Specificity: 0.985\n",
            "F1: 0.908\n",
            "Accuracy： 0.916\n",
            "\n",
            "\n",
            "Model: Transformer\n",
            "AMP classification result:\n",
            "Precision: 0.975\n",
            "Recall: 0.845\n",
            "Specificity: 0.98\n",
            "F1: 0.906\n",
            "Accuracy： 0.913\n",
            "\n",
            "\n",
            "Model: Attention\n",
            "AMP classification result:\n",
            "Precision: 0.975\n",
            "Recall: 0.85\n",
            "Specificity: 0.979\n",
            "F1: 0.908\n",
            "Accuracy： 0.916\n",
            "\n",
            "\n",
            "Model: LSTM\n",
            "AMP classification result:\n",
            "Precision: 0.979\n",
            "Recall: 0.865\n",
            "Specificity: 0.982\n",
            "F1: 0.919\n",
            "Accuracy： 0.925\n",
            "\n",
            "                                               Sequence    CNN  Transformer  \\\n",
            "0                             FIHHIIGGLFSAGKAIHRLIRRRRR  0.725        0.816   \n",
            "1                                    MSTNPKPQRKTKRNTNRR  0.381        0.637   \n",
            "2     SDSHLGDLHKKAVPCKDLVPVVVDILVEHFGAARREREEDEEEEQLGGN  0.283        0.213   \n",
            "3     LIDHLGAPRWAVDTILGAIAVGNLASWVLALVPGPGWAVKAGLATA...  0.416        0.521   \n",
            "4     MSGRGKTGGKARAKAKTRSSRAGLQFPVGRVHRLLRKGNYAHRVGA...  0.418        0.499   \n",
            "...                                                 ...    ...          ...   \n",
            "4516                                     LLLFLLKKRKKRKY  0.714        0.708   \n",
            "4517                               WVPAFCQAVGWGDPITHWSH  0.688        0.639   \n",
            "4518                                     INLKALAALAKALL  0.724        0.708   \n",
            "4519  MLTLKKSLLLLFFLGTINLSLCEEERNADEEETRDDPEERDVDVEK...  0.714        0.747   \n",
            "4520                                       MKSTVPYTSRSR  0.336        0.242   \n",
            "\n",
            "      Attention   LSTM  Ensemble  \n",
            "0         0.670  0.733      True  \n",
            "1         0.666  0.537     False  \n",
            "2         0.280  0.267     False  \n",
            "3         0.284  0.462     False  \n",
            "4         0.662  0.509     False  \n",
            "...         ...    ...       ...  \n",
            "4516      0.675  0.723      True  \n",
            "4517      0.673  0.575      True  \n",
            "4518      0.669  0.731      True  \n",
            "4519      0.667  0.765      True  \n",
            "4520      0.371  0.403     False  \n",
            "\n",
            "[4521 rows x 6 columns]\n",
            "Test result is saved to ./output/classification_result.csv \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AMP-READ"
      ],
      "metadata": {
        "id": "ofMLQhuhvA4b"
      },
      "id": "ofMLQhuhvA4b"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "import argparse\n",
        "from Bio import SeqIO\n",
        "\n",
        "# Parse command-line arguments\n",
        "parser = argparse.ArgumentParser(description=\"AMP Classification\")\n",
        "parser.add_argument(\"--testPath\", type=str, default=\"./data/regression/demo.fasta\", help=\"Path to the test dataset\")\n",
        "parser.add_argument(\"--savePath\", type=str, default=\"output/regression_result.csv\", help=\"Path to save the results\")\n",
        "# args = parser.parse_args()\n",
        "args, unknown = parser.parse_known_args()\n",
        "\n",
        "testPath = args.testPath\n",
        "savePath = args.savePath\n",
        "\n",
        "# Data paths\n",
        "trainPath = \"./data/regression/train.csv\"\n",
        "validatePath = \"./data/regression/test.csv\"\n",
        "\n",
        "\n",
        "# Configuration parameters\n",
        "\n",
        "batch_size = 256\n",
        "MAX_MIC = math.log10(8192)\n",
        "My_MAX_MIC = math.log10(600)\n",
        "\n",
        "\n",
        "# Model paths\n",
        "model_list = {\n",
        "    #\n",
        "    \"CNN\": \"./model/regression/CNN.pth\",\n",
        "    \"Transformer\": \"./model/regression/Transformer.pth\",\n",
        "    \"Attention\": \"./model/regression/Attention.pth\",\n",
        "    \"LSTM\": \"./model/regression/LSTM.pth\",\n",
        "}\n",
        "\n",
        "nameList = model_list.keys()\n",
        "weight = {\"CNN\": 0.25000594, \"Transformer\": 0.2500046, \"Attention\": 0.25000825, \"LSTM\": 0.24998219}\n",
        "\n",
        "mydict = {\"A\": 0, \"C\": 1, \"D\": 2, \"E\": 3, \"F\": 4, \"G\": 5, \"H\": 6, \"I\": 7, \"K\": 8, \"L\": 9, \"M\": 10, \"N\": 11, \"P\": 12, \"Q\": 13, \"R\": 14, \"S\": 15, \"T\": 16, \"V\": 17, \"W\": 18, \"Y\": 19}\n",
        "myInvDict = dict([val, key] for key, val in mydict.items())\n",
        "\n",
        "\n",
        "def fasta_to_csv(fasta_path, csv_path):\n",
        "\n",
        "    sequences = []\n",
        "    lengths = []\n",
        "\n",
        "    for record in SeqIO.parse(fasta_path, \"fasta\"):\n",
        "        sequences.append(str(record.seq))\n",
        "        lengths.append(len(record.seq))\n",
        "\n",
        "    df = pd.DataFrame({\"Sequence\": sequences, \"Length\": lengths})\n",
        "\n",
        "    print(csv_path)\n",
        "    df.to_csv(csv_path, index=False)\n",
        "    return csv_path\n",
        "\n",
        "\n",
        "# transform fasta to csv\n",
        "testPath = fasta_to_csv(testPath, testPath[:-5] + \".csv\")\n",
        "\n",
        "\n",
        "def dataProcessPipeline(seq):\n",
        "\n",
        "    # this function first transform peptide sequences into numerical sequence,\n",
        "    # transformer it into onehot vector and padding them into a fix length\n",
        "    # returning the padding vector and mask\n",
        "\n",
        "    testest = seq\n",
        "    num_seq = [mydict[character.upper()] for character in seq]\n",
        "\n",
        "    seq = np.array(num_seq, dtype=int)\n",
        "    len = seq.shape[0]\n",
        "    torch_seq = torch.tensor(seq)\n",
        "    if torch.sum(torch_seq[torch_seq < 0]) != 0:\n",
        "        print(torch_seq[torch_seq < 0])\n",
        "        print(\"wrong seq:\", seq)\n",
        "        print(testest)\n",
        "    onehotSeq = torch.nn.functional.one_hot(torch_seq, num_classes=20)\n",
        "    # onehotSeq = torch.nn.functional.one_hot(c\n",
        "    pad = torch.nn.ZeroPad2d(padding=(0, 0, 0, 100 - len))\n",
        "    mask = np.zeros(100, dtype=int)\n",
        "    mask[len:] = 1\n",
        "    mask = torch.tensor(mask)\n",
        "\n",
        "    pad_seq = pad(onehotSeq)\n",
        "\n",
        "    return pad_seq, mask\n",
        "\n",
        "\n",
        "class TrainDataset(Dataset):\n",
        "    def __init__(self, data_path, transform=dataProcessPipeline):\n",
        "        df = pd.read_csv(data_path, header=0)\n",
        "\n",
        "        self.df = df\n",
        "\n",
        "        self.seqs = list(self.df[\"Sequence\"])\n",
        "        self.values = self.df[\"value\"]\n",
        "\n",
        "        self.values[self.values > MAX_MIC] = MAX_MIC\n",
        "        self.values = list(self.values)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, idex):\n",
        "        seq = self.seqs[idex]\n",
        "        num_seq, mask = self.transform(seq)\n",
        "        label = self.values[idex]\n",
        "\n",
        "        return num_seq, mask, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.seqs)\n",
        "\n",
        "\n",
        "class TestDataset(Dataset):\n",
        "    def __init__(self, data_path, transform=dataProcessPipeline):\n",
        "        df = pd.read_csv(data_path, header=0)\n",
        "\n",
        "        self.df = df\n",
        "\n",
        "        self.seqs = self.df[\"Sequence\"]\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, idex):\n",
        "        seq = self.seqs[idex]\n",
        "        num_seq, mask = self.transform(seq)\n",
        "\n",
        "        return num_seq, mask, seq\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.seqs)\n",
        "\n",
        "\n",
        "class FastaDataset(Dataset):\n",
        "    def __init__(self, fasta_path, transform=dataProcessPipeline):\n",
        "        self.seqs = [record.seq for record in SeqIO.parse(fasta_path, \"fasta\")]\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        seq = str(self.seqs[index])\n",
        "        num_seq, mask = self.transform(seq)\n",
        "        return num_seq, mask, seq\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.seqs)\n",
        "\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, len, d_model=20, dropout=0):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        pe = torch.zeros(len, d_model)\n",
        "        position = torch.arange(0, len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        # pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer(\"pe\", pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe\n",
        "        # x = x + self.pe[:,:x.size(0), :]\n",
        "        return x\n",
        "\n",
        "\n",
        "class AttentionNetwork(nn.Module):\n",
        "\n",
        "    def __init__(self, batch_size=128, embedding_size=20, num_tokens=100, num_classes=1, num_heads=4):\n",
        "        super(AttentionNetwork, self).__init__()\n",
        "        self.pe = PositionalEncoding(len=num_tokens, d_model=embedding_size)\n",
        "        self.batch_size = batch_size\n",
        "        self.embedding_size = embedding_size\n",
        "        self.num_tokens = num_tokens\n",
        "        self.num_classes = num_classes\n",
        "        self.hidden1 = 20\n",
        "        self.hidden2 = 60\n",
        "        self.hidden3 = 20\n",
        "        self.dropout = 0.2\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        self.LN = nn.LayerNorm(normalized_shape=self.hidden1)\n",
        "        self.fc1 = nn.Linear(self.embedding_size, self.hidden1)\n",
        "\n",
        "        self.multihead_att = nn.MultiheadAttention(embed_dim=self.hidden1, num_heads=self.num_heads, batch_first=1, dropout=self.dropout)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc2 = nn.Linear(self.hidden1 * self.num_tokens, self.hidden2)\n",
        "        self.fc3 = nn.Linear(self.hidden2, self.hidden3)\n",
        "        self.new_fc4 = nn.Linear(self.hidden3, self.num_classes)\n",
        "\n",
        "        self.dropout = nn.Dropout(self.dropout)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        x = self.pe(x)\n",
        "        x = self.fc1(x)\n",
        "\n",
        "        mask = mask.to(torch.bool)\n",
        "        x, w1 = self.multihead_att.forward(x, x, x, key_padding_mask=mask)\n",
        "\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.relu(x)\n",
        "        x = self.fc3(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.new_fc4(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "trainData = TrainDataset(data_path=trainPath)\n",
        "validateData = TrainDataset(data_path=validatePath)\n",
        "testData = TestDataset(data_path=testPath)\n",
        "\n",
        "train_loader = DataLoader(dataset=trainData, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "test_loader = DataLoader(dataset=testData, batch_size=batch_size, shuffle=False)\n",
        "validate_loader = DataLoader(dataset=validateData, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "testData1 = TestDataset(data_path=testPath)\n",
        "test_loader1 = DataLoader(dataset=testData1, batch_size=batch_size, shuffle=0, num_workers=4)\n",
        "\n",
        "\n",
        "frames = []\n",
        "\n",
        "result_df = pd.read_csv(testPath, header=0)\n",
        "\n",
        "model_out = {}\n",
        "for modelName in nameList:\n",
        "\n",
        "    modelPath = model_list[modelName]\n",
        "    modelPreName = modelPath.split(\"/\")[-1][:-4]\n",
        "    id = modelPath.split(\"/\")[-2]\n",
        "    model_out[modelName] = []\n",
        "\n",
        "    t_model = torch.load(modelPath, weights_only=False, map_location='cpu')\n",
        "    t_model.cpu()\n",
        "    if modelName == \"Transformer\":\n",
        "        t_model.postion_embedding.device = \"cpu\"\n",
        "\n",
        "    t_model.zero_grad()\n",
        "\n",
        "    def test_eval(test_loader):\n",
        "        t_model.eval()\n",
        "        total_loss = []\n",
        "        loss_function = nn.MSELoss()\n",
        "        for i, data in enumerate(test_loader):\n",
        "            inputs, masks, labels = data\n",
        "            inputs = inputs.float()\n",
        "            masks = masks.float()\n",
        "            labels = labels.float()\n",
        "\n",
        "            inputs = inputs.cpu()\n",
        "            masks = masks.cpu()\n",
        "            if modelName != \"Attention\":\n",
        "                out = t_model(inputs)\n",
        "            else:\n",
        "                out = t_model(inputs, masks)\n",
        "            out = torch.squeeze(out)\n",
        "\n",
        "            out = out.cpu()\n",
        "            loss = loss_function(out, labels)\n",
        "            total_loss.append(loss.detach().numpy())\n",
        "\n",
        "        ave = np.mean(total_loss)\n",
        "        return ave\n",
        "\n",
        "    loss0 = test_eval(validate_loader)\n",
        "    print(modelName, \" MSE loss in validation set:\", str(loss0))\n",
        "\n",
        "    for i, data in enumerate(test_loader1):\n",
        "        inputs, masks, seqs = data\n",
        "        inputs = inputs.float()\n",
        "        masks = masks.float()\n",
        "\n",
        "        t_model.eval()\n",
        "        inputs = inputs.cpu()\n",
        "        masks = masks.cpu()\n",
        "        if modelName != \"Attention\":\n",
        "            out = t_model(inputs)\n",
        "        else:\n",
        "            out = t_model(inputs, masks)\n",
        "        out = out.cpu()\n",
        "        out_ori = torch.squeeze(out)\n",
        "\n",
        "        out_numpy = list(out_ori.detach().numpy())\n",
        "        out_numpy = [round(v, 3) for v in out_numpy]\n",
        "        model_out[modelName] = list(model_out[modelName]) + out_numpy\n",
        "\n",
        "# summarize the results\n",
        "for k, v in model_out.items():\n",
        "    result_df[k] = v\n",
        "\n",
        "result_df[\"Length\"] = [len(v) for v in result_df[\"Sequence\"]]\n",
        "result_df = result_df[[\"Sequence\", \"Length\", \"CNN\", \"Transformer\", \"Attention\", \"LSTM\"]]\n",
        "df = result_df\n",
        "y = result_df[\"CNN\"] * weight[\"CNN\"] + result_df[\"Transformer\"] * weight[\"Transformer\"] + result_df[\"Attention\"] * weight[\"Attention\"] + result_df[\"LSTM\"] * weight[\"LSTM\"]\n",
        "\n",
        "df[\"Ensemble\"] = [round(v, 3) for v in y]\n",
        "\n",
        "df = df[[\"Sequence\", \"Ensemble\", \"CNN\", \"Transformer\", \"Attention\", \"LSTM\"]]\n",
        "\n",
        "print(df)\n",
        "\n",
        "df.to_csv(savePath, index=0)\n",
        "print(f\"Regression test result is saved to ./{savePath} \")"
      ],
      "metadata": {
        "id": "GWcaHLNsvAAW",
        "outputId": "58a5ea22-2589-4c23-bbe3-f6338691e072",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "GWcaHLNsvAAW",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "./data/regression/demo..csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4217541430.py:109: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self.values[self.values > MAX_MIC] = MAX_MIC\n",
            "/tmp/ipython-input-4217541430.py:109: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self.values[self.values > MAX_MIC] = MAX_MIC\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN  MSE loss in validation set: 0.6175737\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformer  MSE loss in validation set: 0.58181876\n",
            "Attention  MSE loss in validation set: 0.53963906\n",
            "LSTM  MSE loss in validation set: 0.605843\n",
            "                                               Sequence  Ensemble    CNN  \\\n",
            "0       AMDPTKYYGNGVYCNSKKCWVDWGQGSGCIGQTVVGGWLGGAIPGKC    -0.493 -0.674   \n",
            "1     SIEERVKKIIVDQLGAKAEDVKPETSFIEDLGADSLDTVELVMALE...     3.502  2.033   \n",
            "2                        RSVFTKKNGKVFLYVVLLVLAAWRGYALAD     3.297  3.879   \n",
            "3                                 GLLGSLFGAGKKVACALSGLC     1.118  1.348   \n",
            "4                          AGIGTCCGGCMYTTAGGTCCSGIPICAK     1.679  1.889   \n",
            "...                                                 ...       ...    ...   \n",
            "1307    KAVTVVGMGDEGCPGLSSIAANAVAKAQILAGGKRHLDFFLNSPEKK     3.118  2.604   \n",
            "1308                      WHSRVSPGVPYNCKSDQPQPRHMGVSCGV     3.526  2.484   \n",
            "1309                       GGLRSLGRKILRAWKKYGPIIVPIIRIG     0.609  0.872   \n",
            "1310             GLMSLFRGGVLKTAGKHIFKNVGGSLLDQAKCKITGEC     0.678  0.595   \n",
            "1311            DNNAARWTHPLLTGFPVVLEIPVAWGEMDAFQHVNNIFY     3.689  3.867   \n",
            "\n",
            "      Transformer  Attention   LSTM  \n",
            "0          -0.785      0.365 -0.878  \n",
            "1           4.530      3.793  3.651  \n",
            "2           2.117      3.503  3.691  \n",
            "3           1.121      1.235  0.768  \n",
            "4           1.546      1.497  1.784  \n",
            "...           ...        ...    ...  \n",
            "1307        3.397      3.536  2.934  \n",
            "1308        4.056      3.560  4.006  \n",
            "1309        0.662      0.493  0.409  \n",
            "1310        0.582      1.110  0.425  \n",
            "1311        3.844      3.431  3.615  \n",
            "\n",
            "[1312 rows x 6 columns]\n",
            "Regression test result is saved to ./output/regression_result.csv \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EvoGradient"
      ],
      "metadata": {
        "id": "6YeXnSy0v0PN"
      },
      "id": "6YeXnSy0v0PN"
    },
    {
      "cell_type": "code",
      "source": [
        "%cd EvoGradient"
      ],
      "metadata": {
        "id": "92tQFtCtvAg9",
        "outputId": "4532ebc5-ab4c-4e8e-90dc-12105fc146ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "92tQFtCtvAg9",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/AMP-potency-prediction-EvoGradient/EvoGradient\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "import math\n",
        "import warnings\n",
        "import argparse\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Set up argument parser\n",
        "parser = argparse.ArgumentParser(description=\"EvoGradient\")\n",
        "parser.add_argument(\"--peptide\", type=str, default=\"RPLIKLRSTAGTGYTYVTRK\", help=\"Peptide to optimize\")\n",
        "# args = parser.parse_args()\n",
        "args, unknown = parser.parse_known_args()\n",
        "to_opt = args.peptide\n",
        "\n",
        "\n",
        "# Dictionary to map amino acids to numerical values\n",
        "mydict = {\"A\": 0, \"C\": 1, \"D\": 2, \"E\": 3, \"F\": 4, \"G\": 5, \"H\": 6, \"I\": 7, \"K\": 8, \"L\": 9, \"M\": 10, \"N\": 11, \"P\": 12, \"Q\": 13, \"R\": 14, \"S\": 15, \"T\": 16, \"V\": 17, \"W\": 18, \"Y\": 19}\n",
        "# Inverse dictionary to map numerical values back to amino acids\n",
        "myInvDict = dict([val, key] for key, val in mydict.items())\n",
        "MAX_MIC = math.log10(8192)\n",
        "max_mic_buffer = 0.1\n",
        "My_MAX_MIC = math.log10(600)\n",
        "\n",
        "\n",
        "def num2seq(narr, len):\n",
        "    \"\"\"\n",
        "    Convert a numerical array to a sequence of amino acids.\n",
        "\n",
        "    Parameters:\n",
        "    narr (numpy array): Array of numerical values representing amino acids.\n",
        "    len (int): Length of the sequence to return.\n",
        "\n",
        "    Returns:\n",
        "    list: Sequence of amino acids.\n",
        "    \"\"\"\n",
        "    numlist = np.argmax(narr, axis=1)\n",
        "    seq = [myInvDict[value] for value in numlist]\n",
        "    seq = seq[:len]\n",
        "    return seq\n",
        "\n",
        "\n",
        "def colorstr(*input):\n",
        "    \"\"\"\n",
        "    Colors a string using ANSI escape codes.\n",
        "\n",
        "    Parameters:\n",
        "    *input (str): Colors and the string to color.\n",
        "\n",
        "    Returns:\n",
        "    str: Colored string.\n",
        "    \"\"\"\n",
        "    # Colors a string https://en.wikipedia.org/wiki/ANSI_escape_code, i.e.  colorstr('blue', 'hello world')\n",
        "    *args, string = input if len(input) > 1 else (\"blue\", \"bold\", input[0])  # color arguments, string\n",
        "    colors = {\n",
        "        \"black\": \"\\033[30m\",  # basic colors\n",
        "        \"red\": \"\\033[31m\",\n",
        "        \"green\": \"\\033[32m\",\n",
        "        \"yellow\": \"\\033[33m\",\n",
        "        \"blue\": \"\\033[34m\",\n",
        "        \"magenta\": \"\\033[35m\",\n",
        "        \"cyan\": \"\\033[36m\",\n",
        "        \"white\": \"\\033[37m\",\n",
        "        \"bright_black\": \"\\033[90m\",  # bright colors\n",
        "        \"bright_red\": \"\\033[91m\",\n",
        "        \"bright_green\": \"\\033[92m\",\n",
        "        \"bright_yellow\": \"\\033[93m\",\n",
        "        \"bright_blue\": \"\\033[94m\",\n",
        "        \"bright_magenta\": \"\\033[95m\",\n",
        "        \"bright_cyan\": \"\\033[96m\",\n",
        "        \"bright_white\": \"\\033[97m\",\n",
        "        \"end\": \"\\033[0m\",  # misc\n",
        "        \"bold\": \"\\033[1m\",\n",
        "        \"underline\": \"\\033[4m\",\n",
        "    }\n",
        "    return \"\".join(colors[x] for x in args) + f\"{string}\" + colors[\"end\"]\n",
        "\n",
        "\n",
        "def standout(seq1, seq2):\n",
        "    \"\"\"\n",
        "    Compare two sequences and highlight differences.\n",
        "\n",
        "    Parameters:\n",
        "    seq1 (str): First sequence.\n",
        "    seq2 (str): Second sequence.\n",
        "\n",
        "    Returns:\n",
        "    list: Second sequence with differences highlighted.\n",
        "    \"\"\"\n",
        "    # compare bewteen two seqs\n",
        "    index = [1 if seq1[j] == seq2[j] else 0 for j in range(len(seq1))]\n",
        "    newSeq2 = list(seq2)\n",
        "    for i in range(len(seq1)):\n",
        "        if index[i] == 0:\n",
        "            newSeq2[i] = colorstr(\"blue\", seq2[i])\n",
        "\n",
        "    newSeq2 = \"\".join(newSeq2)\n",
        "\n",
        "    return seq1, newSeq2\n",
        "\n",
        "\n",
        "def colorPrint(ls):\n",
        "    \"\"\"\n",
        "    Print the list with colored strings.\n",
        "\n",
        "    Parameters:\n",
        "    ls (list): List of sequences to print.\n",
        "    \"\"\"\n",
        "    newls = [ls[0]]\n",
        "    for i in range(len(ls) - 1):\n",
        "        s1, s2 = standout(ls[i], ls[i + 1])\n",
        "        newls.append(s2)\n",
        "\n",
        "    for i in newls:\n",
        "        print(i)\n",
        "\n",
        "\n",
        "def colorShow(ls):\n",
        "    \"\"\"\n",
        "    Highlight the changes with colored strings.\n",
        "\n",
        "    Parameters:\n",
        "    ls (list): List of sequences to compare and highlight.\n",
        "    \"\"\"\n",
        "    length = len(ls[0])\n",
        "    colorls = [ls[0]]\n",
        "    flag = [0 for i in range(length)]  # record if the position was changed\n",
        "    for i in range(len(ls) - 1):\n",
        "        index = [1 if ls[i][j] == ls[i + 1][j] else 0 for j in range(length)]\n",
        "        for k in range(length):\n",
        "            if index[k] == 0:\n",
        "                flag[k] = 1\n",
        "\n",
        "        colorSeq = list(ls[i + 1])\n",
        "        for k in range(length):\n",
        "            if flag[k] == 1:\n",
        "                colorSeq[k] = colorstr(\"blue\", colorSeq[k])\n",
        "\n",
        "        colorSeq = \"\".join(colorSeq)\n",
        "        colorls.append(colorSeq)\n",
        "\n",
        "    for seq in colorls:\n",
        "        print(seq)\n",
        "\n",
        "\n",
        "def dataProcessPipeline(seq):\n",
        "    \"\"\"\n",
        "    Process a sequence into a padded one-hot encoded tensor and a mask.\n",
        "\n",
        "    Parameters:\n",
        "    seq (str): The input sequence to process.\n",
        "\n",
        "    Returns:\n",
        "    tuple: A tuple containing the padded one-hot encoded tensor and the mask tensor.\n",
        "    \"\"\"\n",
        "    testest = seq\n",
        "    num_seq = [mydict[character.upper()] for character in seq]\n",
        "\n",
        "    seq = np.array(num_seq, dtype=int)\n",
        "    len = seq.shape[0]\n",
        "    torch_seq = torch.tensor(seq)\n",
        "    if torch.sum(torch_seq[torch_seq < 0]) != 0:\n",
        "        print(torch_seq[torch_seq < 0])\n",
        "        print(\"wrong seq:\", seq)\n",
        "        print(testest)\n",
        "    onehotSeq = torch.nn.functional.one_hot(torch_seq, num_classes=20)\n",
        "    pad = torch.nn.ZeroPad2d(padding=(0, 0, 0, 100 - len))\n",
        "    mask = np.zeros(100, dtype=int)\n",
        "    mask[len:] = 1\n",
        "    mask = torch.tensor(mask)\n",
        "\n",
        "    pad_seq = pad(onehotSeq)\n",
        "\n",
        "    return pad_seq, mask\n",
        "\n",
        "\n",
        "def num2onehot(array2d):\n",
        "    \"\"\"\n",
        "    Convert a numerical array to a one-hot encoded tensor.\n",
        "\n",
        "    Parameters:\n",
        "    array2d (torch.Tensor): The input numerical array.\n",
        "\n",
        "    Returns:\n",
        "    torch.Tensor: The one-hot encoded tensor.\n",
        "    \"\"\"\n",
        "    result = torch.zeros_like(array2d)\n",
        "    index = torch.argmax(array2d, dim=-1)\n",
        "    for i in range(index.shape[0]):\n",
        "        result[i, index[i]] = 1\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "# Define the train dataset class\n",
        "class TrainDataset(Dataset):\n",
        "    def __init__(self, data_path, transform=dataProcessPipeline):\n",
        "        \"\"\"\n",
        "        Initialize the dataset.\n",
        "\n",
        "        Parameters:\n",
        "        data_path (str): Path to the CSV file containing the data.\n",
        "        transform (function): Function to process the sequences.\n",
        "        \"\"\"\n",
        "        df = pd.read_csv(data_path, header=0)\n",
        "        df = df[df[\"Length\"] <= 100]\n",
        "        self.df = df\n",
        "        self.seqs = list(self.df[\"Sequence\"])\n",
        "        self.values = self.df[\"value\"]\n",
        "        self.values[self.values > MAX_MIC] = MAX_MIC\n",
        "        self.values = list(self.values)\n",
        "\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, idex):\n",
        "        \"\"\"\n",
        "        Get an item from the dataset.\n",
        "\n",
        "        Parameters:\n",
        "        idex (int): Index of the item to retrieve.\n",
        "\n",
        "        Returns:\n",
        "        tuple: A tuple containing the processed sequence, mask, label, and original sequence.\n",
        "        \"\"\"\n",
        "        seq = self.seqs[idex]\n",
        "        num_seq, mask = self.transform(seq)\n",
        "        label = self.values[idex]\n",
        "\n",
        "        return num_seq, mask, label, seq\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.seqs)\n",
        "\n",
        "\n",
        "# Define the test dataset class\n",
        "class TestDataset(Dataset):\n",
        "    def __init__(self, data_path, transform=dataProcessPipeline):\n",
        "        self.df = pd.read_csv(data_path, header=0)\n",
        "        self.seqs = self.df[\"Sequence\"]\n",
        "\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, idex):\n",
        "        seq = self.seqs[idex]\n",
        "        num_seq, mask = self.transform(seq)\n",
        "\n",
        "        return num_seq, mask, seq\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.seqs)\n",
        "\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, len, d_model=20, dropout=0):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        pe = torch.zeros(len, d_model)\n",
        "        position = torch.arange(0, len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer(\"pe\", pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe\n",
        "        return x\n",
        "\n",
        "\n",
        "pe = PositionalEncoding(len=100, d_model=20)\n",
        "\n",
        "\n",
        "class AttentionNetwork(nn.Module):\n",
        "\n",
        "    def __init__(self, batch_size=128, embedding_size=20, num_tokens=100, num_classes=1, num_heads=4):\n",
        "        super(AttentionNetwork, self).__init__()\n",
        "        self.pe = PositionalEncoding(len=num_tokens, d_model=embedding_size)\n",
        "        self.batch_size = batch_size\n",
        "        self.embedding_size = embedding_size\n",
        "        self.num_tokens = num_tokens\n",
        "        self.num_classes = num_classes\n",
        "        self.num_heads = num_heads\n",
        "        # self.hidden1 = 20\n",
        "        self.hidden1 = 20\n",
        "        self.hidden2 = 60\n",
        "        self.hidden3 = 20\n",
        "        self.dropout = 0.2\n",
        "        self.relu = nn.ReLU()\n",
        "        self.LN = nn.LayerNorm(normalized_shape=self.hidden1)\n",
        "        self.fc1 = nn.Linear(self.embedding_size, self.hidden1)\n",
        "\n",
        "        self.multihead_att = nn.MultiheadAttention(embed_dim=self.hidden1, num_heads=self.num_heads, batch_first=1, dropout=self.dropout)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc2 = nn.Linear(self.hidden1 * self.num_tokens, self.hidden2)\n",
        "        self.fc3 = nn.Linear(self.hidden2, self.hidden3)\n",
        "        self.new_fc4 = nn.Linear(self.hidden3, self.num_classes)\n",
        "        self.dropout = nn.Dropout(self.dropout)\n",
        "        self.softmax = nn.functional.softmax\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        x = self.pe(x)\n",
        "        x = self.fc1(x)\n",
        "\n",
        "        mask = mask.to(torch.bool)\n",
        "        x, w1 = self.multihead_att.forward(x, x, x, key_padding_mask=mask)\n",
        "\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.relu(x)\n",
        "        x = self.fc3(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.new_fc4(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "# use attention model to optimize the sequence for demostration\n",
        "model_list = {\n",
        "    \"Attention\": \"../model/regression/Attention.pth\",\n",
        "}\n",
        "\n",
        "# models used to evaluate the optimized sequences\n",
        "test_model_list = {\"CNN\": \"../model/regression/CNN.pth\", \"Transformer\": \"../model/regression/Transformer.pth\", \"Attention\": \"../model/regression/Attention.pth\", \"LSTM\": \"../model/regression/LSTM.pth\"}\n",
        "\n",
        "opt_seqls = [to_opt]\n",
        "\n",
        "# Set the number of iterations and learning rate for each model\n",
        "iter_dict = {\"CNN\": 500, \"Transformer\": 500, \"Attention\": 500, \"RCNN\": 500}\n",
        "lr_dict = {\"CNN\": 0.01, \"Transformer\": 0.0005, \"Attention\": 0.005, \"RCNN\": 0.001}\n",
        "\n",
        "for seq in opt_seqls:\n",
        "    tseq = seq\n",
        "    ModelNameList = model_list.keys()\n",
        "\n",
        "    oriseq = tseq\n",
        "\n",
        "    # Create a DataFrame to store the sequences, their lengths, and labels\n",
        "    df = pd.DataFrame(columns=[\"Sequence\", \"Length\", \"label\"])\n",
        "    items = [{\"Sequence\": oriseq, \"Length\": len(oriseq)}]\n",
        "\n",
        "    # use _append or append for different pandas version\n",
        "    # df = df.append(items, ignore_index=1)\n",
        "    df = df._append(items, ignore_index=1)\n",
        "\n",
        "    df.to_csv(\"./EvoResult/\" + oriseq + \".csv\", index=False)\n",
        "    SeqPath = \"./EvoResult/\" + oriseq + \".csv\"\n",
        "\n",
        "    testData1 = TrainDataset(data_path=r\"../data/regression/test.csv\")\n",
        "    test_loader1 = DataLoader(dataset=testData1, batch_size=4, drop_last=True)\n",
        "\n",
        "    # Iterate over the models\n",
        "    for modelName in ModelNameList:\n",
        "        alpha = lr_dict[modelName]\n",
        "        iters = iter_dict[modelName]\n",
        "\n",
        "        iternum = 0\n",
        "\n",
        "        testData = TestDataset(data_path=SeqPath)\n",
        "        test_loader = DataLoader(dataset=testData, batch_size=1)\n",
        "        t_model = torch.load(model_list[modelName], weights_only=False, map_location='cpu')\n",
        "        if modelName == \"Transformer\":\n",
        "            t_model.postion_embedding.device = \"cpu\"\n",
        "\n",
        "        t_model.zero_grad()\n",
        "\n",
        "        print(\"Using\", modelName, \" to optimize this sequence:\")\n",
        "        flag = 1\n",
        "\n",
        "        for data in test_loader:\n",
        "            resultList = []\n",
        "            # ensamble_values = []\n",
        "            resultSeq = [oriseq]\n",
        "            outMIC = []\n",
        "            # t_model.zero_grad()\n",
        "            inputs, masks, seqs = data\n",
        "\n",
        "            inputs = inputs.float()\n",
        "            masks = masks.float()\n",
        "\n",
        "            inputs = inputs.cpu()\n",
        "            inputs.requires_grad = True\n",
        "            masks = masks.cpu()\n",
        "            print(seqs[0])\n",
        "\n",
        "            t_model.eval()\n",
        "            for iter in range(iters):\n",
        "                t_model.zero_grad()\n",
        "                inputs.retain_grad = True\n",
        "\n",
        "                if modelName != \"Attention\":\n",
        "                    out = t_model(inputs)\n",
        "                else:\n",
        "                    out = t_model(inputs, masks)\n",
        "\n",
        "                # out = torch.squeeze(out)\n",
        "                out = out.cpu()\n",
        "                conloss = out\n",
        "                conloss.backward()\n",
        "                grad = inputs.grad\n",
        "\n",
        "                colindex = masks[0] == 1\n",
        "                grad[0][masks[0] == 1] = 0\n",
        "                mylen = 100 - colindex.sum()\n",
        "\n",
        "                ori_onehot = num2onehot(inputs[0].cpu())\n",
        "                result = inputs[0] - alpha * grad[0]\n",
        "                result[mylen:, :] = 0\n",
        "                tempt_onehot = num2onehot(result.cpu())\n",
        "\n",
        "                if (tempt_onehot == ori_onehot).all():  # if no AAs (after projection) was changed\n",
        "                    flag = 0\n",
        "                else:\n",
        "                    result = tempt_onehot\n",
        "                    flag = 1\n",
        "                with torch.no_grad():\n",
        "                    inputs[0] = result\n",
        "\n",
        "                result = result.cpu().detach().numpy()\n",
        "                seq = num2seq(result, len=mylen)\n",
        "                seq = \"\".join(seq)\n",
        "                if flag == 1:\n",
        "                    resultSeq.append(seq)\n",
        "\n",
        "        print()\n",
        "        colorShow(resultSeq)\n",
        "        print()\n",
        "\n",
        "        optSeqDir = \"./EvoResult/\" + oriseq\n",
        "        if not os.path.exists(optSeqDir):\n",
        "            os.makedirs(optSeqDir)\n",
        "        optSeqSavePath = optSeqDir + \"/\" + modelName + \".csv\"\n",
        "\n",
        "        result_df = pd.DataFrame(columns=[\"Sequence\", \"label\", \"Length\"])\n",
        "        items = []\n",
        "        for seq in resultSeq:\n",
        "            item = {\"Sequence\": seq, \"Length\": len(seq)}\n",
        "            items.append(item)\n",
        "\n",
        "        # use _append or append for different pandas version\n",
        "        # result_df = result_df.append(items)\n",
        "        result_df = result_df._append(items)\n",
        "\n",
        "        result_df.to_csv(optSeqSavePath)\n",
        "\n",
        "        result_soli = []\n",
        "\n",
        "        testModelNameList = test_model_list.keys()\n",
        "\n",
        "        preList = {}\n",
        "\n",
        "        mylen = result_df.shape[0]\n",
        "        numslist = []\n",
        "\n",
        "        model_out = {}\n",
        "        for testModelName in testModelNameList:\n",
        "            ls = []\n",
        "            model_out[testModelName] = []\n",
        "            testData = TestDataset(data_path=optSeqSavePath)\n",
        "            test_loader = DataLoader(dataset=testData, batch_size=64)\n",
        "\n",
        "            testData1 = TrainDataset(data_path=r\"../data/regression/test.csv\")\n",
        "            test_loader1 = DataLoader(dataset=testData1, batch_size=4, drop_last=True)\n",
        "\n",
        "            t_model = torch.load(test_model_list[testModelName], weights_only=False, map_location='cpu')\n",
        "            if testModelName == \"Transformer\":\n",
        "                t_model.postion_embedding.device = \"cpu\"\n",
        "\n",
        "            t_model.cpu()\n",
        "            t_model.zero_grad()\n",
        "            t_model.eval()\n",
        "\n",
        "            for data in test_loader:\n",
        "                resultList = []\n",
        "                t_model.zero_grad()\n",
        "                inputs, masks, seqs = data\n",
        "                inputs = inputs.float()\n",
        "                masks = masks.float()\n",
        "\n",
        "                inputs = inputs.cpu()\n",
        "                masks = masks.cpu()\n",
        "                t_model.zero_grad()\n",
        "\n",
        "                if testModelName != \"Attention\":\n",
        "                    out = t_model(inputs)\n",
        "                else:\n",
        "                    out = t_model(inputs, masks)\n",
        "\n",
        "                out = out.cpu()\n",
        "                if len(out.shape) > 0:\n",
        "                    out_ori = torch.squeeze(out)\n",
        "                else:\n",
        "                    out_ori = out.unsqueeze(0)\n",
        "\n",
        "                out_numpy = list(out_ori.detach().numpy())\n",
        "                out_numpy = [round(v, 3) for v in out_numpy]\n",
        "                model_out[testModelName] = list(model_out[testModelName]) + out_numpy\n",
        "\n",
        "        # summarize the results\n",
        "        for k, v in model_out.items():\n",
        "            result_df[k] = v\n",
        "        resultPath = optSeqSavePath[:-4] + \"_result.csv\"\n",
        "\n",
        "        ensamble_values = [(result_df[\"Attention\"][k] + result_df[\"Transformer\"][k] + result_df[\"CNN\"][k] + result_df[\"LSTM\"][k]) / 4 for k in range(result_df.shape[0])]\n",
        "        ensamble_values = [round(v, 3) for v in ensamble_values]\n",
        "        result_df[\"Ensemble\"] = ensamble_values\n",
        "\n",
        "        result_df = result_df[[\"Sequence\", \"Ensemble\", \"Length\", \"CNN\", \"Transformer\", \"Attention\", \"LSTM\"]]\n",
        "\n",
        "        result_df.to_csv(resultPath, index=0)\n",
        "        print(f\"Optimization result is saved to ./{resultPath} \")"
      ],
      "metadata": {
        "id": "9LEiCX58wCh_",
        "outputId": "dd59f2a1-30a9-4120-af7e-720c2f5e37d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "9LEiCX58wCh_",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Attention  to optimize this sequence:\n",
            "RPLIKLRSTAGTGYTYVTRK\n",
            "\n",
            "RPLIKLRSTAGTGYTYVTRK\n",
            "RPLIKLR\u001b[34mW\u001b[0mTAGTGYTYVTRK\n",
            "R\u001b[34mK\u001b[0mLIKLR\u001b[34mW\u001b[0mTAGTGYTYVTRK\n",
            "R\u001b[34mK\u001b[0mL\u001b[34mK\u001b[0mKLR\u001b[34mW\u001b[0mTAGTGYTYVTRK\n",
            "R\u001b[34mK\u001b[0mL\u001b[34mK\u001b[0mKLR\u001b[34mW\u001b[0m\u001b[34mR\u001b[0mAGTGYTYVTRK\n",
            "R\u001b[34mK\u001b[0mL\u001b[34mK\u001b[0mKLR\u001b[34mW\u001b[0m\u001b[34mR\u001b[0mAGT\u001b[34mM\u001b[0mYTYVTRK\n",
            "R\u001b[34mK\u001b[0mL\u001b[34mK\u001b[0mKLR\u001b[34mW\u001b[0m\u001b[34mR\u001b[0mAGT\u001b[34mM\u001b[0mY\u001b[34mK\u001b[0mYVTRK\n",
            "R\u001b[34mK\u001b[0mL\u001b[34mK\u001b[0mKLR\u001b[34mW\u001b[0m\u001b[34mR\u001b[0mAG\u001b[34mM\u001b[0m\u001b[34mM\u001b[0mY\u001b[34mK\u001b[0mYVTRK\n",
            "R\u001b[34mK\u001b[0mL\u001b[34mK\u001b[0mKLR\u001b[34mW\u001b[0m\u001b[34mR\u001b[0mAG\u001b[34mM\u001b[0m\u001b[34mM\u001b[0mY\u001b[34mK\u001b[0mYVT\u001b[34mL\u001b[0mK\n",
            "R\u001b[34mK\u001b[0mL\u001b[34mK\u001b[0mKLR\u001b[34mW\u001b[0m\u001b[34mR\u001b[0mAG\u001b[34mM\u001b[0m\u001b[34mM\u001b[0mY\u001b[34mK\u001b[0mYV\u001b[34mK\u001b[0m\u001b[34mL\u001b[0mK\n",
            "\u001b[34mT\u001b[0m\u001b[34mK\u001b[0mL\u001b[34mK\u001b[0mKLR\u001b[34mW\u001b[0m\u001b[34mR\u001b[0mAG\u001b[34mM\u001b[0m\u001b[34mM\u001b[0mY\u001b[34mK\u001b[0mYV\u001b[34mK\u001b[0m\u001b[34mL\u001b[0mK\n",
            "\n",
            "Optimization result is saved to ././EvoResult/RPLIKLRSTAGTGYTYVTRK/Attention_result.csv \n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}